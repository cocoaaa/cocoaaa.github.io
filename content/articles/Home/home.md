Title: Welcome! 
Modified: 2020-01-14  
Template: home  
URL:  
save_as: index.html  
memo: home  
javascripts: https://www.amcharts.com/lib/4/core.js, https://www.amcharts.com/lib/4/charts.js, https://www.amcharts.com/lib/4/maps.js, https://www.amcharts.com/lib/4/geodata/worldLow.js, https://www.amcharts.com/lib/4/geodata/usaTerritoriesLow.js, https://www.amcharts.com/lib/4/themes/animated.js, https://www.amcharts.com/lib/4/plugins/timeline.js,  my_trajectory.js
stylesheets: my_trajectory.css

<div id="chartdiv" height="400"></div>
<div id="mapdiv" height="600"></div>

I'm a 2nd year PhD @ USC studying the lower-dimensional representation of complex unstructured datasets (eg. multi-spectral satellite images, 3D MRI scans) using deep learning. My work lies in the intersection of statistical machine learning, information theory and coding theory.  I also work on interactive visualization of high-dimensional datasets and complex models (eg. deep neural nets) for a guide to better insight and understanding.

- Information Distillation across domain and modality: Variational Autoencoder
- Invariance in representation: information-theory, "nuisance"
- Dynamics of learning in neural networks: initialization, normalization
    - non-linear and chaos theory
    - emergence
    - information geometry

Before my PhD, I was at MIT studying Mathematics and EECS (Electrical Engineering and Computer Science) for my undergraduate and Masters. After Masters, I interned at Apple as a coop for 9 months.  I also worked on a cool French robotics startup (Keecker) and several academic research labs (MIT CSAIL, MIT Media Lab and INRIA) during my studies.


<!--![my-trajectory](/images/my-trajectory.png)-->
More about [me](/pages/about-me.html) and papers [here](/pages/publications.html).

---
More on my research interest 

I'm interested in distilling the informational content from the representational structure imposed by domain-specific structures (eg. natural  images satisfy and define a set of  rules that make us('intelligent' entities) to recognize them as 'natural' images,  whereas there is an implicit  set of rules that defines what a proper 'English' sentence (as opposed to 'French' language or a video data).   also work on understanding the dynamics of neural networks from information-theoretic perspectives. 



## Recent updates
- I gave my first tutorial @ PyData LA, 2019 on "Experimental ML with Holoviews/Geoviews + Pyorch". Here are my talk [slides](/pdfs/experimental-ml-2019-hayley.pdf), [video](#), and [jupyter notebook materials](https://github.com/cocoaaa/PyData-LA-2019)!

| | | |
|---|---|---|
|![pydata-0](/images/pydata-0.png)|![pydata-1](/images/pydata-1.png)|![pydata-1-2](/images/pydata-1-2.png) |
|![pydata-2](/images/pydata-2.png)|![pydata-3](/images/pydata-3.png)| ![pydata-4](/images/pydata-4.png)|

- I participated in [Geo4Good](https://sites.google.com/earthoutreach.org/geoforgood19/home) @ Google in Mtn View, CA! Check out some [highlights](https://tinyurl.com/wdoyepy) of inspiring project going on using Google Earth Engine and Studio. 
- New post: "Total variation, KL-Divergence, Maximum Likelihood"
- New post: "Let's be honest: peeling the assumptions that get us to Variational Autoencoders"
- New post: "Thinking about an observer vs. the observed"

## What am I upto?
- Actively looking for a fun, challenging, meaningful internship
- Working on a cool paper using variational autoencoder on geospatial data

---
#### TMI ('Too Much Information')

More importantly, I'm practicing to:
- observe without being entangled emotionally and(?) physically
- look at small thoughts carefully
- not to rush
- spend most of time on what matters most
- be gentle and be slow
- be curious
- question
- continuously bring stochasity to the current model of world as I believe and,
- hopefully replace my old thinking and habits with more conscious choices and freer future

