Title: Knowledge-Distillation papers
Status: draft

## Compiled List
- [Awesome Knowledge-Distillation](https://github.com/FLHonker/Awesome-Knowledge-Distillation)

## Knowledge-Distillation and Lower-Dim Representation
- Knowledge Distillation from Internal Representations. Aguillar et al. 

## Knowledge-Distillation and Semantics
- TandemNet: Distilling Knowledge from Medical Images Using Diagnostic Reports as Optional Semantic References. Zhang Zizhao. MICCAI 2017 

## Application to computer vision
### semantic segmentation
- Structured Knowledge Distillation for Semantic Segmentation.  AAAI 2020
 - Distilling Pixel-Wise feature Similarities for Semantic Segmentation. Yuhu Shan 2019. [arXivL1910.14226v1](https://arxiv.org/pdf/1910.14226.pdf)