<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Small Simplicity</title>
    <link rel="shortcut icon" type="image/png" href="https://cocoaaa.github.io/favicon.png">
    <link rel="shortcut icon" type="image/x-icon" href="https://cocoaaa.github.io/favicon.ico">
    <link href="https://cocoaaa.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Small Simplicity Full Atom Feed" />

    <!--[if lte IE 8]>
        <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
         <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css">
    <!--<![endif]-->

    <link href="https://fonts.googleapis.com/css?family=Fira+Code:wght@500|Fira+Sans+Condensed|Cantarell|VT323&display=swap" rel="stylesheet">


    <link rel="stylesheet" href="https://cocoaaa.github.io/theme/css/screen.css" type="text/css" />
    <link rel="stylesheet" href="https://cocoaaa.github.io/theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="https://cocoaaa.github.io/theme/css/print.css" type="text/css" media="print" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="" />
    <meta name="author" content="Hayley Song" />
</head>

<body>
    <header>
        <!-- here: add menu items for navbar -->
        <nav> 
            <ul>
                <li><a href="https://cocoaaa.github.io/">Home</a></li>
                <li><a href="https://cocoaaa.github.io/pages/about-me">About</a></li>
                <li><a href="https://cocoaaa.github.io/pages/publications">Publications</a></li>
                <li><a href="https://cocoaaa.github.io/pages/projects">Projects</a></li>
                <li><a href="https://cocoaaa.github.io/blog_index">Blog</a></li>
            </ul>
        </nav>
        <div class="header_box">
            <h1><a href="https://cocoaaa.github.io/">Small Simplicity</a></h1>
            <h2>Understanding Intelligence from Computational Perspective</h2>
        </div>
    </header>

<!-- here: main content section's css -->
    <div id="wrapper" class="pure-g">

        <div id="content pure-u-1 pure-u-md-4-5">
            <div class="page">
                <h1>About me - old</h1>
                <div align="center">
<img alt="profile" src="/images/profile.jpg" width="250"/>
</div>
<p><br/></p>
<div align="center">
<a href="/docs/hjsong_cv.pdf"><img alt="cv" src="/images/cv1.png" width="40"/></a>
<a href="https://github.com/cocoaaa"><img alt="@cocoaaa" src="/images/github.svg" width="40"/></a>
<a href="/pages/publications.html"><img alt="projects" src="/images/lightbulb3.svg" width="40"/></a>
</div>
<p>Hello!  I'm a PhD student at <strong>University of Southern California</strong> (USC) 
in Computer Science, studying the dynamics of neural networks using information-theoretic approach and extracting lower dimensional
representation of complex, unstructured geospatial datasets like multi-spectral satellite images.</p>
<h2 id="research-interest">Research interest</h2>
<ul>
<li>the <strong>interpretability</strong> and <strong>transferability</strong> of deep neural networks, and</li>
<li>hybrid intelligent systems that incorporate <strong>knowledge-based 
(symbolic) AI</strong> to <strong>neural networks</strong></li>
</ul>
<p>At USC, I'm working with 
Prof. <a href="https://yaoyichi.github.io/">Yao-Yi Chiang</a> at the <a href="http://spatial-computing.github.io/">Spatial Computing and Informatics</a> lab and Prof. <a href="http://usc-isi-i2.github.io/knoblock/">Craig Knoblock</a> 
at ISI's <a href="http://usc-isi-i2.github.io/home/">Center on Knowledge Graphs</a>.</p>
<p>Before USC, I studied at <strong>Massachusetts Institute of Technology</strong> Mathematics and Electrical Engineering and Computer Science (EECS)
for my Bachelors and Masters.
During my Masters, I concentrated on Artificial Intelligence and worked under the joint 
guidance of Professor <a href="https://people.csail.mit.edu/regina/">Regina Barzilay</a>, 
Professor <a href="http://people.csail.mit.edu/wojciech/">Wojciech Matusik</a>, and Dr. 
<a href="http://people.csail.mit.edu/jstraub/">Julian Straub</a>. My main projects were 
(1) image registration of mammograms for breast cancer detection, and (2) 3D reconstruction of human arms for efficient <a href="https://mayocl.in/2S5khTZ">lymphedema</a> screening.  You can find out more about them <a href="/pages/publications.html">here</a></p>
<!--
- Build a camera system using 8 RGBD sensors (eg. Intel RealSense)
- Reconstruct 3D models of human arms from RGBD images
- Non-rigid registration of mammogram images using optical flow algorithms
-->
<p>My current projects focus on using reasoning and deep neural networks to understand 
complex <strong>spatio-temporal</strong> data collected from satellites. </p>
<ul>
<li><a href="#">Semantic Road</a>: </li>
<li><a href="#">MINT</a>: </li>
<li><a href="#">Model Poker</a>:</li>
</ul>
<p>Please see my <a href="/pages/publications.html">project</a> page for more details. </p>
<hr/>
<h2 id="knowledge-representation-in-learning-and-generalization">Knowledge representation in Learning and Generalization</h2>
<p><span class="videobox">
<iframe allowfullscreen="" frameborder="0" height="390" mozallowfullscreen="" src="https://www.youtube.com/embed/ow7eEWh37iU" webkitallowfullscreen="" width="640">
</iframe>
</span></p>
<h2 id="lingering-questions">Lingering questions</h2>
<p>In a bigger scheme, I am excited about the problems regarding human perception of 
the world and how symbolic representation of knowledge can facilitate learning 
in a new domain [via knowledge transfer across various domains/modalities].  I'm 
continuously exploring these questions in my research:</p>
<ol>
<li>How can intelligent agents learn with less supervision, particularly in the domain of 
vision and three-dimensional perception (<todo>:spatial reasonging?)<ul>
<li>via autonomously interacting with the environment</li>
<li>via incorporating external knowledge </li>
<li>via incorporating common sense reasoning</li>
</ul>
</todo></li>
</ol>
<p>My current <a href="#semantic_road_project">project</a> on road detection from satellite images explores 
this question using external geospatial knowledge base (OpenStreetMap) and reinforcement
learning. <!-- todo: transfer learning? --></p>
<ol>
<li>How can those knowledge be represented in a more abstract form so that it can be used for 
learning in different domains 
(keyword: <a href="#">Knowledge Representation</a>, <a href="#">Transfer Learning</a>/<a href="#">Domain Adaptation</a>)</li>
</ol>
<h2 id="softwares">Softwares</h2>
<p>I use Python (eg. <strong>PyTorch</strong>, Numpy, scikit-learn) for machine learning
<a href="#">projects</a> and C++ for hardware systems (eg. Microsoft Kinnect and Intel RealSense)
as in <a href="#">this</a> project. </p>
<hr/>
<p>Besides working on my projects, I enjoy being in nature and trying out different sports. 
Along the way, I became a certified scuba diver and have sky-dived in Czech sky! 
I enjoy biking and swimming -- they help me connect to the dimension that 
is not about thinking and analyzing, and remind me we are more than our 
thoughts and minds. I enjoy sharing such experiences with friends:)</p>
<hr/>
<!--
{% img ../images/profile.jpg %}  
<div align="center"> 
    <img src="/images/profile.jpg" alt="profile" width="250"/>
    <ul>
      <li><a href="/docs/hjsong_cv.pdf"><img src="/images/cv1.svg" alt="cv" width="50"/><a></li>
      <li><a href="https://github.com/cocoaaa"><img src="/images/github.svg" alt="@cocoaaa" width="50" /><a></li>
      <li><a href="/pages/projects.html"><img src="/images/lightbulb3.svg" alt="projects" width="50"/><a></li>
    </ul>
</div>



    <a href="/docs/hjsong_cv.pdf"><img src="/images/cv1.svg" alt="cv" width="50"/><a>
    <a href="https://github.com/cocoaaa"><img src="/images/github.svg" alt="@cocoaaa" width="50" /><a>
    <a href="/pages/projects.html"><img src="/images/rocket1.svg" alt="projects" width="50"/><a>
    <a href="/pages/projects.html"><img src="/images/rocket2.svg" alt="projects" width="50"/><a>
    <a href="/pages/projects.html"><img src="/images/lightbulb1.svg" alt="projects" width="50"/><a>
    <a href="/pages/projects.html"><img src="/images/lightbulb2.svg" alt="projects" width="50"/><a>
    <a href="/pages/projects.html"><img src="/images/lightbulb3.svg" alt="projects" width="50"/><a>

 we can use our understandings of the world to develop intelligent systems 
that can interactive with the dynamic environments as we, humans, do. 



I am interested in combining the geometric 
understandings with the semanic interpretations of a scene as the first step towards this goal. 






---
Previously, I worked in image registration (aka. Optical Flow) and three-dimensional perception computer vision and 
how human intelligence can efficiently learn via interaction with the
environments as well as ho
interaction and intelligent systems that what we call 'intelligence' is, particularly in the domain of 
vision, perception and knowledge representation.  One way to study it is via reverse-engineer 
artificial systems that can computer vision and three-dimensional perception.

Understanding of the functional and causal relations between objects in a visual scene
Holistic scene interpretation by combining the semantic and geometric knowledge about 
2D images and 3D data (such as RGB-D) 

Recognition: What makes us recognize an object 
as what it is (e.g. a bird as a bird, a bull as a bull)? What is the necessary and 
sufficient representation of an object for human recognition? This question has been 
lingering on my mind ever since I saw a video of Picasso at work:

---
  I'm a machine learning researcher studying how intelligence can be 
computationally modeled and used to solve challenging social and 
environmental problems.  

the potential synergy between symbolic AI and deep learning 
incorporating knowledge and reasoning-based artificial intelligence to current 
deep learning approaches. 
reasoning.  I'm interested in bridging the how human intelligence can be
computationally modelled and MIT EECS (concentration: AI) pursuing a Masters in Engineering under the joint supervision of Professor Regina Barzilay, Professor Wojciech Matusik, and a Ph.D candidate, Julian Straub. Before my Masters, I studied Mathematics and EECS at MIT for my undergraduate studies.

I'm curious about what we call 'intelligence', especially in the domain of computer vision and three-dimensional perception.

Understanding of the functional and causal relations between objects in a visual scene
Holistic scene interpretation by combining the semantical and geometric information from 2D images and 3D data (such as RGB-D)
Recognition: What makes us recognize an object as what it is (e.g. a bird as a bird, a bull as a bull)? What is the necessary and sufficient representation of an object for human recognition? This question has been lingering on my mind ever since I saw a video of Picasso at work:

-->
            </div>

            <div class="clear"></div>
            <footer>
                <p>
                <a href="https://github.com/jody-frankowski/blue-penguin">Blue Penguin</a> Theme
                &middot;
                Powered by <a href="http://getpelican.com">Pelican</a>
                &middot;
                <a href="https://cocoaaa.github.io/feeds/all.atom.xml" rel="alternate">Atom Feed</a>
            </footer>
        </div>
        <div class="clear"></div>
    </div>
</body>


</html>