Title: front page

## concise Intro to who I was, who I am <!--todo-->
<p class="codepen" data-height="1050" data-theme-id="default" data-default-tab="result" data-user="cocoaaa" data-slug-hash="PoweddN" style="height: 1050px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;" data-pen-title="Day and Night World Map">
  <span>See the Pen <a href="https://codepen.io/cocoaaa/pen/PoweddN">
  Day and Night World Map</a> by Hayley Song (<a href="https://codepen.io/cocoaaa">@cocoaaa</a>)
  on <a href="https://codepen.io">CodePen</a>.</span>
</p>
<script async src="https://static.codepen.io/assets/embed/ei.js"></script>

I'm a 2nd year PhD @ USC studying the lower-dimensional representation of complex unstructured datasets (eg. multi-spectral satellite images, 3D MRI scans) using deep learning. My work lies in the intersection of statistical machine learning, information theory and coding theory.  I also work on interactive visiaulization of high-dimensional datasets and complex models (eg. deep neural nets) for a guide to better insight and understanding.

- Information Distillation across domain and modality: Variational Autoencoder
- Invariance in representation: information-theory, "nuisance"
- Dynamics of learning in neural networks: initialization, normalization
    - non-linear and chaos theory
    - emergence
    - information geometry

Before my PhD, I was at MIT studying Mathematics and EECS (Electrical Engineering and Computer Science) for my undergraduate and Masters. After Masters, I interned at Apple as a coop for 9 months.  I also worked on a cool French robotics startup (Keecker) and several academic research labs (MIT CSAIL, MIT Media Lab and INRIA) during my studies.


![my-trajectory](/images/my-trajectory.png)

More about me and papers [here](#)<!--todo-->

---
More on my research interest 

I'm interested in distilling the informational content from the representational structure imposed by domain-specific structures (eg. natural  images satisfy and define a set of  rules that make us('intelligent' entities) to recognize them as 'natural' images,  whereas there is an implicit  set of rules that defines what a proper 'English' sentence (as opposed to 'French' langauge or a video data).   also work on understanding the dynamics of neural networks from information-theoretic perspectives. 



## Recent updates
- I gave my first tutorial @ PyData LA, 2019 on "Experimental ML with Holoviews/Geoviews + Pyorch". Here are my [talk](#) and [materials](https://github.com/cocoaaa/PyData-LA-2019)!
- I participated in [Geo4Good](https://sites.google.com/earthoutreach.org/geoforgood19/home) @ Google in Mtn View, CA! Check out some [highlights](#) of inspiring project going on in Google Earth Engine and Studio. <!-- todo --> 
- New post: "Total variation, KL-Divergence, Maximum Likelihood"
- New post: "Let's be honest: peeling the assumptions that get us to Variational Autoencoders"
- New post: "Thinking about an observer vs. the observed"

## What am I upto?
- Actively looking for a fun, challenging, meaningful internship
- Working on a cool paper using variational autoencoder on geospatial data

---
#### TMI ('Too Much Information')

More importantly, I'm practicing to:
- observe without being entangled emotionally and(?) physically
- look at small thoughts carefully
- not to rush
- spend most of time on what matters most
- be gentle and be slow
- be curious
- question
- continuously bring stochasity to the current model of world as I believe and,
- hopefully replace my old thinking and habits with more conscious choices and freer future

